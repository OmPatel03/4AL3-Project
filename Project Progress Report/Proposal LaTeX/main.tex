\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[]{acl}
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Group X Progress Report:\\My Group's Project Name}


\author{First Author, Second Author, Third Author \\
  \texttt{\{macid1,macid2,macid3\}@mcmaster.ca} }

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
% \begin{abstract}
% \end{abstract}

\section{Introduction}

Online dating systems usually optimize for clicks or stated preferences, not mutual compatibility. We study the problem of predicting an individual’s ideal partner profile from structured demographic, preference, and ratings data. Given a person A, our model first predicts the set of people A would likely say "yes" to, then composes a representative partner profile B* from the top-k candidates. Next, it predicts who B* would likely say "yes" to, producing a second composite C*. The difference between A and C* captures a preference gap that reveals why A’s most desired partners may prefer someone different. This framing supports both recommendation and self-insight, and it generalizes to other matching settings such as mentorship and team formation.

We focus on the Columbia Speed Dating dataset, a tabular dataset with 8,378 rows and 123 columns, and formulate the task as classification for the yes or no decision with ranking objectives layered on top for recommendation quality. Our goals are: (1) build a leakage-free, explainable pipeline that predicts A’s decision on B, (2) construct B* and C* to surface preference gaps, and (3) evaluate with Accuracy, F1, ROC-AUC, and Precision@k.

\section{Related Work}

Our work is informed by several research areas. The first is the original analysis of our dataset, the Columbia Speed Dating Experiment, where Fisman and Iyengar found that attractiveness, fun, and shared interests were highly predictive of matching decisions. Second, our A→B→C loop concept is inspired by two-sided matching theory, most famously represented by the Gale-Shapley algorithm, which underscores that stable matches must account for the preferences of both sides. Third, our approach is related to the broader field of recommender systems, which often use collaborative or content-based filtering to predict preferences, though typically not in a two-hop "preference gap" framework. Fourth, we draw from psychological research on partner preferences, such as the meta-analysis by Finkel, Eastwick, and colleagues, which reviewed the predictive validity of stated ideal partner preferences. Finally, given our goal of providing insights, our work connects to explainable AI (XAI) methods, such as SHAP, which we plan to use to identify which features most influence compatibility predictions.
\section{Dataset}

We are using the Columbia Speed Dating dataset, as described in our proposal. It consists of \textbf{8,378 observations} (individual dates) and \textbf{123 columns}.
\subsection{Preprocessing and Cleaning}

The raw dataset required significant preprocessing. Our pipeline performs the following steps:
\begin{itemize}
    \item \textbf{String Decoding:} Many text columns were encoded as Python byte literals (e.g., `b'female'`). We decoded these into standard UTF-8 strings.
    \item \textbf{Normalization:} All string values were converted to lowercase and stripped of leading/trailing whitespace to ensure consistency (e.g., "Law" and "law" are treated as identical).
    \item \textbf{Missing Values:} We unified various missing value markers (e.g., "na", "n/a", "", "nan") into a single `pd.NA` representation.
    \item \textbf{Numeric Coercion:} Columns that appeared to be numeric but were stored as objects (e.g., "1.0", "5") were automatically coerced into floating-point types, while preserving categorical ranges (e.g., "[0-1]").
\end{itemize}

This stable ID generation is crucial for our participant-based train-test split.

\section{Features}

The model inputs were derived exclusively from pre-event survey responses in the Speed Dating dataset to ensure fairness and avoid post-event leakage. Each training example represents a pairing between two participants (A and B), with features combining demographic, self-assessment, and preference information from both sides.

For participant A, features included demographic attributes (age, gender, race, and field of study), self-ratings (\texttt{attractive}, \texttt{sincere}, \texttt{intelligence}, \texttt{funny}, \texttt{ambition}), personal interests (e.g., \texttt{sports}, \texttt{music}, \texttt{movies}, \texttt{reading}, \texttt{exercise}, \texttt{hiking}, \texttt{art}, \texttt{shopping}), and stated partner preferences (\texttt{attractive\_important}, \texttt{sincere\_important}, etc.). 

For participant B, corresponding partner features were used, including demographic information (\texttt{age\_o}, \texttt{gender\_o}, \texttt{race\_o}), self-ratings (\texttt{attractive\_o}, \texttt{sinsere\_o}, \texttt{intelligence\_o}, \texttt{funny\_o}, \texttt{ambitous\_o}), and stated partner preferences (\texttt{pref\_o\_attractive}, \texttt{pref\_o\_sincere}, etc.). This alignment allowed the model to learn the relationship between what A looks for in a partner and how B describes themselves.

Feature engineering included converting all byte-encoded categorical fields to strings, coercing numeric columns to float representations, and one-hot encoding categorical attributes. We also computed derived attributes such as age difference and same-race indicators to capture potential compatibility signals. No explicit dimensionality reduction or learned embeddings were applied at this stage, as the dataset’s moderate size made full feature inclusion tractable.

No additional feature selection was used beyond excluding post-event data (\texttt{like}, \texttt{match}, \texttt{decision\_o}) to prevent leakage. Future iterations may explore feature importance rankings from the trained model to prune redundant or weakly predictive features and to better interpret the contribution of personality versus demographic factors.


\section{Implementation}

We implemented a binary classification model to predict whether a participant (A) would say ``yes'' to another participant (B) using pre-event survey data from the Speed Dating dataset. The target label is the \texttt{decision} column, where 1 indicates ``yes'' and 0 indicates ``no.''

Our baseline model is a simple majority class predictor, which always predicts ``no'' and achieves approximately 58\% accuracy (reflecting the dataset's 58/42 class split). This serves as a lower bound for model performance.

For our primary model, we used a calibrated XGBoost classifier, which is a tree-based gradient boosting algorithm well-suited for mixed numeric and categorical data. The model was trained using log loss (binary cross-entropy) as the objective function, optimized through gradient boosting with decision trees. We applied isotonic calibration on validation data to ensure that predicted probabilities better reflected true likelihoods.

The input features included both A's and B's survey responses: demographic variables (age, gender, race, field), self-ratings, interest scores, and partner preference indicators (\texttt{\textasteriskcentered important} and \texttt{pref\_o\_\textasteriskcentered}). To prevent data leakage, we excluded all post-event information such as \texttt{like}, \texttt{match}, and \texttt{decision\_o}.

Training, validation, and testing were split at the participant level rather than by row to avoid information overlap between sets. Optimization used XGBoost's default gradient-based tree boosting with early stopping. Current results yield accuracy $\approx 0.63$, F1 $\approx 0.51$, and ROC-AUC $\approx 0.66$, a notable improvement over the baseline.

Implementation challenges mainly involved cleaning the dataset (many categorical columns were stored as byte strings) and balancing interpretability with model complexity. Our next step is to extend this model to the A~$\rightarrow$~B~$\rightarrow$~C pipeline, where predictions are used to simulate and analyze multi-stage preference dynamics.


\section{Results and Evaluation}
The model was evaluated using participant-level data splits to ensure that no individual appeared in multiple subsets, preventing information leakage across training and testing. The dataset was divided into 70\% training, 15\% validation, and 15\% testing sets. This structure allowed for model tuning on the validation set and unbiased performance assessment on unseen participants.

We used a calibrated XGBoost classifier with isotonic calibration applied on the validation data. Calibration was verified using reliability curves and the Brier score to assess the alignment between predicted probabilities and observed outcomes.

Evaluation focused on standard binary classification metrics, including accuracy, precision, recall, F1 score, and ROC-AUC. These metrics collectively measured both discrimination ability and balance between false positives and false negatives. The final model achieved an accuracy of approximately 0.63, F1 score of 0.51, and ROC-AUC of 0.66, representing a meaningful improvement over the 0.58 baseline accuracy from the majority-class predictor.

While we did not employ full cross-validation due to computational constraints, the participant-level split provides a robust approximation of generalization. Future work will consider k-fold validation and top-K ranking metrics (e.g., Precision@K) to better evaluate recommendation-style extensions of the A~$\rightarrow$~B~$\rightarrow$~C pipeline.

\section{Feedback and Plans}

Write about your plans for the remainder of the project. This should include a discussion of the feedback you received from your TA, and how you plan to improve your approach. Reflect on your implementation and areas for improvement. Refer to item 6. This may be around 0.5 pages.

\section{Template Notes}

You can remove this section or comment it out, as it only contains instructions for how to use this template. You may use subsections in your document as you find appropriate.

\subsection{Tables and figures}

See Table~\ref{citation-guide} for an example of a table and its caption.
See Figure~\ref{fig:experiments} for an example of a figure and its caption.


\begin{figure}[t]
  \includegraphics[width=\columnwidth]{example-image-golden}
  \caption{A figure with a caption that runs for more than one line.
    Example image is usually available through the \texttt{mwe} package
    without even mentioning it in the preamble.}
  \label{fig:experiments}
\end{figure}

\begin{figure*}[t]
  \includegraphics[width=0.48\linewidth]{example-image-a} \hfill
  \includegraphics[width=0.48\linewidth]{example-image-b}
  \caption {A minimal working example to demonstrate how to place
    two images side-by-side.}
\end{figure*}


\subsection{Citations}

\begin{table*}
  \centering
  \begin{tabular}{lll}
    \hline
    \textbf{Output}           & \textbf{natbib command} & \textbf{ACL only command} \\
    \hline
    \citep{Gusfield:97}       & \verb|\citep|           &                           \\
    \citealp{Gusfield:97}     & \verb|\citealp|         &                           \\
    \citet{Gusfield:97}       & \verb|\citet|           &                           \\
    \citeyearpar{Gusfield:97} & \verb|\citeyearpar|     &                           \\
    \citeposs{Gusfield:97}    &                         & \verb|\citeposs|          \\
    \hline
  \end{tabular}
  \caption{\label{citation-guide}
    Citation commands supported by the style file.
  }
\end{table*}

Table~\ref{citation-guide} shows the syntax supported by the style files.
We encourage you to use the natbib styles.
You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Gusfield:97}.
You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Gusfield:97}.
You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Gusfield:97}).

\subsection{References}

\nocite{Ando2005,andrew2007scalable,rasooli-tetrault-2015}

Many websites where you can find academic papers also allow you to export a bib file for citation or bib formatted entry. Copy this into the \texttt{custom.bib} and you will be able to cite the paper in the \LaTeX{}. You can remove the example entries.

\subsection{Equations}

An example equation is shown below:
\begin{equation}
  \label{eq:example}
  A = \pi r^2
\end{equation}

Labels for equation numbers, sections, subsections, figures and tables
are all defined with the \verb|\label{label}| command and cross references
to them are made with the \verb|\ref{label}| command.
This an example cross-reference to Equation~\ref{eq:example}. You can also write equations inline, like this: $A=\pi r^2$.


% \section*{Limitations}

\section*{Team Contributions}

Write in this section a few sentences describing the contributions of each team member. What did each member work on? Refer to item 7.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{custom,anthology-overleaf-1,anthology-overleaf-2}

% Custom bibliography entries only
\bibliography{custom}

% \appendix

% \section{Example Appendix}
% \label{sec:appendix}

% This is an appendix.

\end{document}
