\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[]{acl}
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.


\title{Group 51 Progress Report:\\The Optimal Match Model: Predicting Ideal Partner with ML}


\author{Alvin Qian , Om Patel, Gregory Archer \\
  \texttt{\{qiana2,patelo11,archeg1\}@mcmaster.ca} }


%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
% \begin{abstract}
% \end{abstract}

\section{Introduction}

Online dating platforms often optimize for engagement metrics such as clicks, swipes, or stated preferences rather than genuine mutual compatibility. Many systems therefore prioritize popularity or activity rather than understanding the bidirectional nature of attraction. In this project, we study the problem of predicting an individual's ideal partner profile from structured demographic, preference, and rating data. Our goal is not only to identify who a person is likely to say ``yes'' to but also to infer what kind of person would, in turn, find them compatible.

Given a participant A, our model predicts the set of individuals A would likely respond positively to, based on their recorded preferences and historical choices. From the top-$k$ candidates, we generate a composite partner profile $B^*$ representing the aggregated traits of A’s most desired matches. The model then predicts who $B^*$ would be most likely to say ``yes'' to, forming another representative profile $C^*$. Comparing A and $C^*$, referred to as the preference gap, highlights asymmetries between what an individual seeks and what those they desire tend to prefer. This framing offers insight into unreciprocated attraction and the dynamics of compatibility, while providing both recommendation value and interpretability.

The task is formulated as a binary classification problem (predicting the ``yes'' or ``no'' decision) with ranking-based evaluation to measure recommendation quality. Our objectives are threefold:
\begin{enumerate}
    \item Build a leakage-free, explainable pipeline that predicts an individual’s decision outcome.
    \item Construct the composite profiles $B^*$ and $C^*$ for analyzing preference gaps.
    \item Evaluate performance using metrics such as Accuracy, F1 score, ROC-AUC, and Precision@k.
\end{enumerate}




\section{Related Work}

Our work is informed by several research areas. The first is the original analysis of our dataset, the Columbia Speed Dating Experiment, where Fisman and Iyengar found that attractiveness, fun, and shared interests were highly predictive of matching decisions. Second, our A→B→C loop concept is inspired by two-sided matching theory \citep{Roth:online}, most famously represented by the Gale-Shapley algorithm, which underscores that stable matches must account for the preferences of both sides. Third, our approach is related to the broader field of recommender systems, which often use collaborative or content-based filtering to predict preferences, though typically not in a two-hop "preference gap" framework. Fourth, we draw from psychological research on partner preferences, such as the meta-analysis by \citet{Eastwick:2014}, which reviewed the predictive validity of stated ideal partner preferences. Finally, given our goal of providing insights, our work connects to explainable AI (XAI) methods, such as SHAP, which we plan to use to identify which features most influence compatibility predictions.
\section{Dataset}

We are using the Columbia Speed Dating dataset, as described in our proposal. It consists of \textbf{8,378 observations} (individual dates) and \textbf{123 columns}.
\subsection{Preprocessing and Cleaning}

The raw dataset required significant preprocessing. Our pipeline performs the following steps:
\begin{itemize}
    \item \textbf{String Decoding:} Many text columns were encoded as Python byte literals (e.g., `b'female'`). We decoded these into standard UTF-8 strings.
    \item \textbf{Normalization:} All string values were converted to lowercase and stripped of leading/trailing whitespace to ensure consistency (e.g., "Law" and "law" are treated as identical).
    \item \textbf{Missing Values:} We unified various missing value markers (e.g., "na", "n/a", "", "nan") into a single `pd.NA` representation.
    \item \textbf{Numeric Coercion:} Columns that appeared to be numeric but were stored as objects (e.g., "1.0", "5") were automatically coerced into floating-point types, while preserving categorical ranges (e.g., "[0-1]").
\end{itemize}

This stable ID generation is crucial for our participant-based train-test split.


\section{Features}

The model inputs were derived exclusively from pre-event survey responses in the Speed Dating dataset to ensure fairness and avoid post-event leakage. Each training example represents a pairing between two participants (A and B), with features combining demographic, self-assessment, and preference information from both sides. Using only pre-date data ensures that the model learns compatibility patterns rather than reactions or biases formed during the actual event.

For participant A, features included demographic attributes (age, gender, race, and field of study), self-ratings (attractive, sincere, intelligence, funny, ambition), personal interests (e.g., sports, music, movies, reading, exercise, hiking, art, shopping), and stated partner preferences (attractive\_important, sincere\_important, etc.). For participant B, corresponding partner features were used, including demographic information (age\_o, gender\_o, race\_o), self-ratings (attractive\_o, sincere\_o, intelligence\_o, funny\_o, ambitious\_o), and stated partner preferences (pref\_o\_attractive, pref\_o\_sincere, etc.). This alignment allowed the model to learn the relationship between what A looks for in a partner and how B describes themselves, creating a symmetric and interpretable feature space.

Feature engineering included converting all byte-encoded categorical fields to strings, coercing numeric columns to float representations, and one-hot encoding categorical attributes. Derived attributes such as age difference and same-race indicators were added to capture potential compatibility signals. Missing demographic or preference values were imputed using the mode for categorical features and the median for numerical ones to maintain data consistency without distorting distributional properties. All numerical features were normalized to a [0,1] range to ensure balanced model learning, particularly for tree-based methods that may otherwise overweight higher-magnitude attributes.

No explicit dimensionality reduction or learned embeddings were applied at this stage, as the dataset’s moderate size made full feature inclusion tractable. However, future iterations may experiment with principal component analysis (PCA) or learned latent embeddings to capture higher-order interactions between traits. We also plan to use model-based feature importance scores (e.g., from XGBoost or SHAP values) to identify redundant or weakly predictive inputs and better interpret the contribution of personality versus demographic variables to match likelihood. These interpretive tools will guide future pruning and feature weighting decisions, improving both transparency and model efficiency.


\section{Implementation}

We implemented a binary classification model to predict whether a participant (A) would say ``yes'' to another participant (B) using pre-event survey data from the Speed Dating dataset. The target label is the \texttt{decision} column, where 1 indicates ``yes'' and 0 indicates ``no.'' The modeling process was designed to ensure reproducibility, fairness, and the avoidance of post-event data leakage.

Our baseline model is a simple majority class predictor that always predicts ``no,'' achieving approximately 58\% accuracy. This baseline corresponds to the dataset’s natural class imbalance (58/42 split) and serves as a lower bound for meaningful model comparison.

For our primary model, we used a calibrated XGBoost classifier, a gradient-boosted decision tree model known for its robustness to heterogeneous data types and ability to capture nonlinear feature interactions. The model was trained using binary cross-entropy (log loss) as the objective function, optimized via additive tree boosting. We performed hyperparameter tuning using randomized search over parameters such as \texttt{max\_depth}, \texttt{learning\_rate}, \texttt{subsample}, and \texttt{n\_estimators}, balancing predictive performance and overfitting risk. Early stopping was used with a validation patience of 50 rounds to halt training when no further improvement was observed.

To improve probability calibration, we applied isotonic regression on validation outputs so that predicted probabilities aligned more closely with empirical decision frequencies. This calibration step was important for interpretability, as our later analyses depend on comparing predicted likelihoods across simulated participants rather than binary outputs alone.

The input features included both A’s and B’s pre-event survey responses: demographic variables (age, gender, race, and field of study), self-assessments (attractiveness, sincerity, intelligence, humor, ambition), personal interests, and partner preference indicators (\texttt{\_important} and \texttt{pref\_o\_}). Post-event attributes such as \texttt{like}, \texttt{match}, and \texttt{decision\_o} were excluded to prevent label leakage.

Data splits were performed at the participant level rather than by row, ensuring that information about any one participant did not appear in multiple sets. The data were divided into training (70\%), validation (15\%), and test (15\%) partitions. Model optimization followed XGBoost’s gradient-based boosting with learning rate scheduling, and results were tracked using both cross-validation and held-out evaluation.

Current results yield an accuracy of approximately 0.63, F1 score of 0.51, and ROC-AUC of 0.66, representing a clear improvement over the 0.58 baseline. Feature importance analysis shows that self-rated attractiveness, shared interests, and age difference are among the most influential predictors of a positive decision.

Implementation challenges primarily involved dataset cleaning and ensuring interpretability. Many categorical fields were stored as byte strings requiring decoding and normalization, and balancing explainability with model complexity remained an ongoing consideration. Future iterations will extend this framework into the A~$\rightarrow$~B~$\rightarrow$~C pipeline to simulate multi-stage preference dynamics and analyze how compatibility signals propagate across indirect match predictions.


\section{Results and Evaluation}

Model evaluation is ongoing, with current experiments focused on establishing baseline performance and validating the modeling pipeline. All results reported here are preliminary and based on the current version of the calibrated XGBoost classifier.

The dataset was divided into 70\% training, 15\% validation, and 15\% testing sets, split at the participant level to ensure that no individual appeared in multiple subsets. This setup prevents information leakage and provides an unbiased framework for model tuning and evaluation.

We trained an XGBoost classifier using binary cross-entropy loss and applied isotonic calibration on validation predictions to improve probability reliability. Calibration quality was assessed using reliability curves and the Brier score, which provided early indications that the model’s predicted probabilities align reasonably well with observed outcomes.

Evaluation focuses on standard binary classification metrics, including accuracy, precision, recall, F1 score, and ROC-AUC. These metrics are being used to assess both discrimination ability and class balance. Preliminary results show an accuracy around 0.63, F1 score near 0.51, and ROC-AUC of approximately 0.66, which represents a moderate improvement over the 0.58 baseline from the majority-class predictor. While these numbers are expected to evolve with further tuning and feature refinement, they suggest that pre-event attributes carry meaningful predictive information.

Ongoing work involves refining hyperparameters, experimenting with alternative model architectures, and expanding evaluation to include ranking-based metrics such as Precision@k. We also plan to incorporate SHAP-based feature importance analysis to better understand which demographic and personality factors most strongly influence predicted compatibility scores. Future iterations will integrate these insights into the A~$\rightarrow$~B~$\rightarrow$~C pipeline to evaluate how prediction quality scales in multi-stage matching.



\section{Feedback and Plans}

The feedback provided by our TA emphasized three key areas for improvement: establishing a clear baseline model for comparison, expanding evaluation metrics beyond accuracy and F1 score, and including more experimental details such as hyperparameters, visualizations, and training summaries. These points align well with our current development roadmap and will guide our next phase of work.

First, we plan to formalize the baseline by implementing and reporting results for multiple simple models, such as logistic regression and decision trees, in addition to the majority-class predictor. This will help contextualize our XGBoost model’s performance and quantify improvement more concretely. We will also include baseline metrics in a results table for clarity.

Second, we aim to broaden our evaluation by incorporating additional performance metrics. In particular, we plan to include Precision@k and Mean Reciprocal Rank (MRR) to better capture the model’s ranking capability. Potentially the Brier score and reliability curves to evaluate calibration quality as well. These metrics will provide a more nuanced understanding of both predictive accuracy and probabilistic reliability, which are important for the planned A~$\rightarrow$~B~$\rightarrow$~C compatibility framework.

Third, we will expand the experimental section to include visual and quantitative summaries of model behavior. Planned additions include feature importance plots from XGBoost and SHAP, learning curves showing convergence trends, and calibration plots comparing predicted and observed probabilities. These visualizations will make our analysis more interpretable and strengthen the report’s empirical depth.

Finally, we recognize opportunities to refine the implementation itself. We intend to conduct more extensive hyperparameter tuning using randomized or Bayesian optimization, experiment with additional ensemble models (e.g., LightGBM or CatBoost), and evaluate whether dimensionality reduction or latent embeddings improve performance. We also plan to explore balancing techniques such as class weighting or SMOTE to mitigate the dataset’s inherent imbalance.

Overall, the TA’s feedback provided clear and actionable directions. Our remaining work will focus on strengthening the experimental rigor, improving interpretability, and extending the analysis to the full A~$\rightarrow$~B~$\rightarrow$~C pipeline. These steps will help ensure that our final model is both robust and explainable, providing a more comprehensive understanding of human compatibility prediction.



% \begin{figure}[t]
%   \includegraphics[width=\columnwidth]{example-image-golden}
%   \caption{A figure with a caption that runs for more than one line.
%     Example image is usually available through the \texttt{mwe} package
%     without even mentioning it in the preamble.}
%   \label{fig:experiments}
% \end{figure}

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{plots/true_false_positives.png}
  \caption{Distribution of predicted probabilities by actual outcome, showing the model's ability to discriminate between true positives and true negatives.}
  \label{fig:true-false-positives}
\end{figure*}

% \subsection{Citations}


% Table~\ref{citation-guide} shows the syntax supported by the style files.
% We encourage you to use the natbib styles.
% You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Eastwick:2014}.
% You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Roth:online}.
% You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Eastwick:2014}).

% \subsection{References}

% Many websites where you can find academic papers also allow you to export a bib file for citation or bib formatted entry. Copy this into the \texttt{custom.bib} and you will be able to cite the paper in the \LaTeX{}. You can remove the example entries.

% \subsection{Equations}

% An example equation is shown below:
% \begin{equation}
%   \label{eq:example}
%   A = \pi r^2
% \end{equation}

% Labels for equation numbers, sections, subsections, figures and tables
% are all defined with the \verb|\label{label}| command and cross references
% to them are made with the \verb|\ref{label}| command.
% This an example cross-reference to Equation~\ref{eq:example}. You can also write equations inline, like this: $A=\pi r^2$.


% \section*{Limitations}

\section*{Team Contributions}

Write in this section a few sentences describing the contributions of each team member. What did each member work on? Refer to item 7.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{custom,anthology-overleaf-1,anthology-overleaf-2}

% Custom bibliography entries only
\bibliography{custom}

\newpage
\section*{Tables and Figures}

Table~\ref{tab:top10-recommendations} shows the top 10 recommended partners for a sample participant A, ranked by predicted compatibility score (p\_AB). The table illustrates the model's ability to identify high-potential matches based on pre-event survey data.

\begin{table*}[t]
\centering
\footnotesize
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}cccccccccccccccc@{}}
\hline
\textbf{ID} & \textbf{Gen.} & \textbf{Age} & \textbf{Race} & \textbf{Field} & \textbf{Att.} & \textbf{Sin.} & \textbf{Int.} & \textbf{Fun.} & \textbf{Amb.} & \textbf{Spo.} & \textbf{Mus.} & \textbf{Mov.} & \textbf{Rea.} & \textbf{Exe.} & \textbf{p\_AB} \\
\hline
137 & F & 29 & Oth. & Music Ed. & 9 & 10 & 9 & 9 & 8 & 8 & 10 & 9 & 5 & 10 & 0.64 \\
439 & F & 27 & Eur. & Finance & 8 & 10 & 10 & 9 & 10 & 7 & 10 & 10 & 5 & 10 & 0.64 \\
367 & F & 26 & Lat. & Law & 9 & 9 & 9 & 9 & 9 & 8 & 9 & 9 & 7 & 7 & 0.64 \\
199 & F & 29 & Eur. & Psychology & 7 & 8 & 4 & 8 & 8 & 6 & 6 & 7 & 7 & 4 & 0.64 \\
198 & F & 28 & Eur. & Social Work & 9 & 8 & 5 & 9 & 3 & 6 & 6 & 9 & 9 & 5 & 0.64 \\
369 & F & 28 & Eur. & German Lit. & 7 & 10 & 7 & 10 & 7 & 1 & 10 & 10 & 10 & 5 & 0.64 \\
370 & F & 29 & Oth. & Psychology & 7 & 9 & 9 & 9 & 9 & 3 & 9 & 7 & 5 & 9 & 0.64 \\
194 & F & 22 & Eur. & Social Work & 8 & 9 & 7 & 10 & 7 & 8 & 5 & 7 & 9 & 5 & 0.64 \\
382 & F & 22 & Eur. & Comm. & 7 & 9 & 9 & 9 & 4 & 2 & 10 & 10 & 4 & 1 & 0.64 \\
383 & F & 22 & Eur. & Social Work & 6 & 8 & 8 & 8 & 8 & 7 & 10 & 8 & 6 & 10 & 0.64 \\
\hline
\end{tabular}
\caption{Top 10 recommended partners for sample participant A. Abbreviations: Gen.=Gender, Att.=Attractive, Sin.=Sincere, Int.=Intelligence, Fun.=Funny, Amb.=Ambition, Spo.=Sports, Mus.=Music, Mov.=Movies, Rea.=Reading, Exe.=Exercise, Eur.=European/Caucasian-American, Lat.=Latino/Hispanic, Oth.=Other, Comm.=Communications, Ed.=Education, Lit.=Literature.}
\label{tab:top10-recommendations}
\end{table*}

Table~\ref{tab:composite-profile} presents the composite profile B*, constructed by averaging the characteristics of the top 10 recommended partners shown in Table~\ref{tab:top10-recommendations}. This aggregated profile represents the ``ideal partner type'' that participant A would most likely prefer, based on the model's predictions.

\begin{table}[h]
\centering
\begin{tabular}{@{}lr@{}}
\hline
\textbf{Attribute} & \textbf{Value} \\
\hline
Age & 26.2 \\
Attractive & 7.7 \\
Sincere & 9.0 \\
Intelligence & 7.7 \\
Funny & 9.0 \\
Ambition & 7.3 \\
Sports & 5.6 \\
Music & 8.5 \\
Movies & 8.6 \\
Reading & 6.7 \\
Exercise & 6.6 \\
Gender & Female \\
Race & European/Caucasian-American \\
Field & Social Work \\
\hline
\end{tabular}
\caption{Composite profile B* derived by averaging the top 10 recommended partners for participant A. Numeric values represent means across all candidates; categorical values represent the mode (most common value).}
\label{tab:composite-profile}
\end{table}

% \appendix

% \section{Example Appendix}
% \label{sec:appendix}

% This is an appendix.

\end{document}
