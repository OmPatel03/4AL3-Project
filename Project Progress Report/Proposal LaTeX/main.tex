\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[]{acl}
\usepackage{times}
\usepackage{latexsym}
\usepackage{float} % 

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.


\title{Group 51 Progress Report:\\The Optimal Match Model: Predicting Ideal Partner with ML}


\author{Alvin Qian , Om Patel, Gregory Archer \\
  \texttt{\{qiana2,patelo11,archeg1\}@mcmaster.ca} }


%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
% \begin{abstract}
% \end{abstract}

\section{Introduction}

Online dating platforms often optimize for engagement metrics such as clicks, swipes, or stated preferences rather than genuine mutual compatibility. Many systems therefore prioritize popularity or activity rather than understanding the bidirectional nature of attraction. In this project, we study the problem of predicting an individual's ideal partner profile from structured demographic, preference, and rating data. Our goal is not only to identify who a person is likely to say ``yes'' to but also to infer what kind of person would, in turn, find them compatible.

Given a participant A, our model predicts the set of individuals A would likely respond positively to, based on their recorded preferences and historical choices. From the top-$k$ candidates, we generate a composite partner profile $B^*$ representing the aggregated traits of A’s most desired matches. The model then predicts who $B^*$ would be most likely to say ``yes'' to, forming another representative profile $C^*$. Comparing A and $C^*$, referred to as the preference gap, highlights asymmetries between what an individual seeks and what those they desire tend to prefer. This framing offers insight into unreciprocated attraction and the dynamics of compatibility, while providing both recommendation value and interpretability.

The task is formulated as a binary classification problem (predicting the ``yes'' or ``no'' decision) with ranking-based evaluation to measure recommendation quality. Our objectives are threefold:
\begin{enumerate}
    \item Build a leakage-free, explainable pipeline that predicts an individual’s decision outcome.
    \item Construct the composite profiles $B^*$ and $C^*$ for analyzing preference gaps.
    \item Evaluate performance using metrics such as Accuracy, F1 score, ROC-AUC, and Precision@k.
\end{enumerate}




\section{Related Work}

Our work is informed by several research areas. The first is the original analysis of our dataset, the Columbia Speed Dating Experiment, where Fisman and Iyengar found that attractiveness, fun, and shared interests were highly predictive of matching decisions. Second, our A→B→C loop concept is inspired by two-sided matching theory \citep{Roth:online}, most famously represented by the Gale-Shapley algorithm, which underscores that stable matches must account for the preferences of both sides. Third, our approach is related to the broader field of recommender systems, which often use collaborative or content-based filtering to predict preferences, though typically not in a two-hop "preference gap" framework. Fourth, we draw from psychological research on partner preferences, such as the meta-analysis by \citet{Eastwick:2014}, which reviewed the predictive validity of stated ideal partner preferences. Finally, given our goal of providing insights, our work connects to explainable AI (XAI) methods, such as SHAP, which we plan to use to identify which features most influence compatibility predictions.
\section{Dataset}

We are using the Columbia Speed Dating dataset, as described in our proposal. It consists of \textbf{8,378 observations} (individual dates) and \textbf{123 columns}.
\subsection{Preprocessing and Cleaning}

The raw dataset required significant preprocessing. Our pipeline performs the following steps:
\begin{itemize}
    \item \textbf{String Decoding:} Many text columns were encoded as Python byte literals (e.g., `b'female'`). We decoded these into standard UTF-8 strings.
    \item \textbf{Normalization:} All string values were converted to lowercase and stripped of leading/trailing whitespace to ensure consistency (e.g., "Law" and "law" are treated as identical).
    \item \textbf{Missing Values:} We unified various missing value markers (e.g., "na", "n/a", "", "nan") into a single `pd.NA` representation.
    \item \textbf{Numeric Coercion:} Columns that appeared to be numeric but were stored as objects (e.g., "1.0", "5") were automatically coerced into floating-point types, while preserving categorical ranges (e.g., "[0-1]").
\end{itemize}

\section{Features}

Our model inputs were derived entirely from pre-event survey responses in the Speed Dating dataset to avoid post-event leakage and ensure that predictions reflected true compatibility rather than impressions formed during the event. Each training example represents a pairing between two participants (A and B), and the model receives features describing both individuals. This allows the classifier to learn relationships between what A wants in a partner and how B presents themselves, as well as broader patterns of interpersonal compatibility.

\subsection{Base Feature Set}

For participant A, we included demographic attributes (age, gender, race, field of study), self-assessment ratings (attractive, sincere, intelligent, funny, ambitious), personal interests (e.g., sports, music, movies, reading, exercise, hiking, art, shopping), and stated partner preferences (such as \texttt{attractive\_important} and \texttt{sincere\_important}). For participant B, we incorporated the corresponding partner-side features: demographic attributes (age\_o, gender\_o, race\_o), self-ratings (\texttt{attractive\_o}, \texttt{sincere\_o}, \texttt{intelligence\_o}, etc.), and B's stated preferences for a partner (\texttt{pref\_o\_attractive}, \texttt{pref\_o\_sincere}, etc.). This symmetry ensures that the model observes both what A is seeking and what B offers.

Categorical variables were decoded from byte strings and then one-hot encoded. Numeric values were coerced into consistent formats, but no scaling was required since tree-based models are insensitive to feature magnitude.

\subsection{Interaction and Augmented Features}

In addition to the base features, we experimented with an augmented ``rich'' feature set that incorporated all non-leaky \texttt{d\_*} interaction columns present in the dataset. These columns encode differences between A and B along various traits, such as \texttt{d\_age}, \texttt{d\_attractive}, \texttt{d\_funny}, and \texttt{d\_music}. Including these relative-difference features is motivated by the literature on mate selection, which emphasizes alignment and distance between partners rather than absolute traits alone. Our ablation results confirmed this intuition: the model performed substantially better when interaction features were included.

\subsection{Rationale}

It is natural to include both absolute features (e.g., age, interests, personality) and relative features (e.g., age gap, rating differences), since attraction depends simultaneously on individual attributes and their compatibility. Partner preference variables (\texttt{\_important} and \texttt{pref\_o\_}) were included because prior psychological studies show that stated preferences predict real choices to a moderate degree. Interest-based features were included because similarity in hobbies has been shown to influence perceived compatibility.

\subsection{Feature Experiments}

We compared two main feature configurations:

\begin{enumerate}
    \item \textbf{Base Pre-Event Features}—demographics, interests, self-ratings, and preference indicators.
    \item \textbf{Augmented Features with Interaction Deltas}—the base set plus all non-leaky \texttt{d\_*} difference features.
\end{enumerate}

This variation allowed us to directly measure the contribution of relational features. Models trained on the rich feature set consistently outperformed those trained on the base set, indicating that the differences between A and B were critical for accurate prediction.

No dimensionality reduction or learned embeddings were used, as the feature dimensionality was manageable and tree-based models naturally handle large sparse inputs. Future work may explore representation learning or feature pruning informed by model-based importance scores (e.g., SHAP values) to improve interpretability.


\section{Implementation}

We implemented a series of binary classification models to predict whether a participant (A) would say ``yes'' to another participant (B) using only pre-event survey features from the Speed Dating dataset. The prediction target is the \texttt{decision} label, where 1 indicates a positive response and 0 a negative one. All modeling decisions were made to prevent post-event leakage and ensure fair, reproducible evaluation. Although the broader goal of the project includes the A~$\rightarrow$~B~$\rightarrow$~C pipeline for analyzing multi-stage compatibility patterns, the implementation described here focuses on building the core predictive model that underlies that pipeline.

\subsection{Baselines}

Our simplest baseline is a majority-class classifier that always predicts ``no.'' Since the dataset is imbalanced (approximately 58\% negative and 42\% positive decisions), this baseline achieves 58\% accuracy but an F1 score of 0. This provides a conservative lower bound and highlights the necessity of learning meaningful structure beyond class priors.

As a stronger baseline, we trained a logistic regression model with one-hot encoded categorical variables. This model achieved modest improvements (accuracy $\approx$ 0.60, ROC-AUC $\approx$ 0.62), demonstrating that linear models capture some predictive structure but are insufficient for modeling the complex, nonlinear preference patterns in the dataset.

\subsection{Primary Models}

Our primary approach uses gradient-boosted decision trees. We experimented with two variants:

\begin{itemize}
    \item \textbf{HistGradientBoostingClassifier (HGB)}, a fast, histogram-based gradient-boosting model suitable for tabular data.
    \item \textbf{XGBoost}, a state-of-the-art gradient-boosting framework offering strong regularization and flexible tree construction.
\end{itemize}

Both models were trained with the binary cross-entropy (log loss) objective, optimized via additive boosting. Hyperparameters such as \texttt{max\_depth}, \texttt{learning\_rate}, \texttt{subsample}, and \texttt{n\_estimators} were tuned through randomized search. Early stopping on a held-out validation set prevented overfitting and greatly reduced training time.

Categorical variables were encoded using a \texttt{ColumnTransformer} with one-hot encoding, while numeric features were passed through unchanged. Since probability quality is important for downstream analysis, we applied isotonic regression to calibrate model outputs, ensuring that predicted probabilities accurately reflected empirical decision frequencies.

\subsection{Feature Variants and Ablations}

We evaluated two feature variants:

\begin{enumerate}
    \item \textbf{Base Feature Set:} demographics, self-ratings, preferences, and interests available from pre-event surveys.
    \item \textbf{Rich Feature Set with Interaction Deltas:} an augmented feature set including all non-leaky interaction columns of the form \texttt{d\_*}, which quantify differences between A and B (e.g., age difference, rating gaps, interest mismatch).
\end{enumerate}

These ablations allowed us to isolate the contribution of interaction features. The interaction-enhanced model performed substantially better, indicating that relational differences between A and B are highly predictive of attraction decisions. These findings are consistent with prior literature on partner preference alignment.

\subsection{Optimization Strategy}

Participants were partitioned at the individual level to avoid having the same person appear in multiple splits. Data were divided into 70\% training, 15\% validation, and 15\% testing. All optimization followed XGBoost's gradient-boosting procedure, with subsampling-based regularization and early stopping to prevent overfitting. Model selection was based on validation ROC-AUC.

\subsection{Results}

Using the base feature set, our calibrated XGBoost model achieved accuracy $\approx$ 0.63, F1 $\approx$ 0.51, and ROC-AUC $\approx$ 0.66, outperforming both baselines. Incorporating interaction deltas led to a substantial improvement: the interaction-enhanced XGBoost model achieved accuracy $\approx$ 0.73, F1 $\approx$ 0.70, and ROC-AUC $\approx$ 0.80. These results demonstrate that gradient-boosted tree models effectively capture pre-event compatibility and provide a strong foundation for our planned A~$\rightarrow$~B~$\rightarrow$~C compatibility pipeline.

While we implemented an initial version of the pipeline earlier in the project using a simpler model, the primary focus of this report is the construction and evaluation of the final predictive models themselves. The improved probability calibration and richer feature representations documented here position the model to support more reliable downstream analyses—including A’s top predicted partners (B), the composite “ideal partner” profile (B$^\ast$), and B$^\ast$’s preferred matches (C)—in future extensions of the project.


\section{Results and Evaluation}

Model evaluation is ongoing, with current experiments focused on establishing baseline performance and validating the modeling pipeline. All results reported here are preliminary and based on the current version of the calibrated XGBoost classifier.

The dataset was divided into 70\% training, 15\% validation, and 15\% testing sets, split at the participant level to ensure that no individual appeared in multiple subsets. This setup prevents information leakage and provides an unbiased framework for model tuning and evaluation.

We trained an XGBoost classifier using binary cross-entropy loss and applied isotonic calibration on validation predictions to improve probability reliability. Calibration quality was assessed using reliability curves and the Brier score, which provided early indications that the model’s predicted probabilities align reasonably well with observed outcomes.

Evaluation focuses on standard binary classification metrics, including accuracy, precision, recall, F1 score, and ROC-AUC. These metrics are being used to assess both discrimination ability and class balance. Preliminary results show an accuracy around 0.63, F1 score near 0.51, and ROC-AUC of approximately 0.66, which represents a moderate improvement over the 0.58 baseline from the majority-class predictor. While these numbers are expected to evolve with further tuning and feature refinement, they suggest that pre-event attributes carry meaningful predictive information.

Ongoing work involves refining hyperparameters, experimenting with alternative model architectures, and expanding evaluation to include ranking-based metrics such as Precision@k. We also plan to incorporate SHAP-based feature importance analysis to better understand which demographic and personality factors most strongly influence predicted compatibility scores. Future iterations will integrate these insights into the A~$\rightarrow$~B~$\rightarrow$~C pipeline to evaluate how prediction quality scales in multi-stage matching.



\section{Feedback and Plans}

The feedback provided by our TA emphasized three key areas for improvement: establishing a clear baseline model for comparison, expanding evaluation metrics beyond accuracy and F1 score, and including more experimental details such as hyperparameters, visualizations, and training summaries. These points align well with our current development roadmap and will guide our next phase of work.

First, we plan to formalize the baseline by implementing and reporting results for multiple simple models, such as logistic regression and decision trees, in addition to the majority-class predictor. This will help contextualize our XGBoost model’s performance and quantify improvement more concretely. We will also include baseline metrics in a results table for clarity.

Second, we aim to broaden our evaluation by incorporating additional performance metrics. In particular, we plan to include Precision@k and Mean Reciprocal Rank (MRR) to better capture the model’s ranking capability. Potentially the Brier score and reliability curves to evaluate calibration quality as well. These metrics will provide a more nuanced understanding of both predictive accuracy and probabilistic reliability, which are important for the planned A~$\rightarrow$~B~$\rightarrow$~C compatibility framework.

Third, we will expand the experimental section to include visual and quantitative summaries of model behavior. Planned additions include feature importance plots from XGBoost and SHAP, learning curves showing convergence trends, and calibration plots comparing predicted and observed probabilities. These visualizations will make our analysis more interpretable and strengthen the report’s empirical depth.

Finally, we recognize opportunities to refine the implementation itself. We intend to conduct more extensive hyperparameter tuning using randomized or Bayesian optimization, experiment with additional ensemble models (e.g., LightGBM or CatBoost), and evaluate whether dimensionality reduction or latent embeddings improve performance. We also plan to explore balancing techniques such as class weighting or SMOTE to mitigate the dataset’s inherent imbalance.

Overall, the TA’s feedback provided clear and actionable directions. Our remaining work will focus on strengthening the experimental rigor, improving interpretability, and extending the analysis to the full A~$\rightarrow$~B~$\rightarrow$~C pipeline. These steps will help ensure that our final model is both robust and explainable, providing a more comprehensive understanding of human compatibility prediction.



% \begin{figure}[t]
%   \includegraphics[width=\columnwidth]{example-image-golden}
%   \caption{A figure with a caption that runs for more than one line.
%     Example image is usually available through the \texttt{mwe} package
%     without even mentioning it in the preamble.}
%   \label{fig:experiments}
% \end{figure}

% \subsection{Citations}


% Table~\ref{citation-guide} shows the syntax supported by the style files.
% We encourage you to use the natbib styles.
% You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Eastwick:2014}.
% You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Roth:online}.
% You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Eastwick:2014}).

% \subsection{References}

% Many websites where you can find academic papers also allow you to export a bib file for citation or bib formatted entry. Copy this into the \texttt{custom.bib} and you will be able to cite the paper in the \LaTeX{}. You can remove the example entries.

% \subsection{Equations}

% An example equation is shown below:
% \begin{equation}
%   \label{eq:example}
%   A = \pi r^2
% \end{equation}

% Labels for equation numbers, sections, subsections, figures and tables
% are all defined with the \verb|\label{label}| command and cross references
% to them are made with the \verb|\ref{label}| command.
% This an example cross-reference to Equation~\ref{eq:example}. You can also write equations inline, like this: $A=\pi r^2$.


% \section*{Limitations}

\section*{Team Contributions}

Om led the model development and implementation process, including data preprocessing, feature engineering, and training the XGBoost classifier. He also integrated the calibration and evaluation framework and coordinated the A~$\rightarrow$~B~$\rightarrow$~C pipeline design.

Gregory focused on exploratory data analysis, dataset cleaning, and the construction of participant-level profiles. He was responsible for identifying key features from the survey data and preparing visualizations and summary statistics used in both the report and presentation materials.

Alvin contributed to the experimental design and evaluation setup, helping define baseline comparisons and select appropriate performance metrics. He also supported documentation, result interpretation, and report writing, ensuring clarity and consistency across all sections.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{custom,anthology-overleaf-1,anthology-overleaf-2}

% Custom bibliography entries only
\bibliography{custom}

\clearpage
\onecolumn
\section*{Tables and Figures}

% Table~\ref{tab:top10-recommendations} shows the top 10 recommended partners for a sample participant A, ranked by predicted compatibility score (p\_AB). The table illustrates the model's ability to identify high-potential matches based on pre-event survey data.
\begin{figure}[H]
  \raggedright
  \includegraphics[width= \textwidth]{plots/true_false_positives.png}
  \caption{Distribution of predicted probabilities by actual outcome, showing the model's ability to discriminate between true positives and true negatives.}
  \label{fig:true-false-positives}
\end{figure}

\begin{table}[H]
\raggedright
\footnotesize
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}cccccccccccccccc@{}}
\hline
\textbf{ID} & \textbf{Gen.} & \textbf{Age} & \textbf{Race} & \textbf{Field} & \textbf{Att.} & \textbf{Sin.} & \textbf{Int.} & \textbf{Fun.} & \textbf{Amb.} & \textbf{Spo.} & \textbf{Mus.} & \textbf{Mov.} & \textbf{Rea.} & \textbf{Exe.} & \textbf{p\_AB} \\
\hline
137 & F & 29 & Oth. & Music Ed. & 9 & 10 & 9 & 9 & 8 & 8 & 10 & 9 & 5 & 10 & 0.64 \\
439 & F & 27 & Eur. & Finance & 8 & 10 & 10 & 9 & 10 & 7 & 10 & 10 & 5 & 10 & 0.64 \\
367 & F & 26 & Lat. & Law & 9 & 9 & 9 & 9 & 9 & 8 & 9 & 9 & 7 & 7 & 0.64 \\
199 & F & 29 & Eur. & Psychology & 7 & 8 & 4 & 8 & 8 & 6 & 6 & 7 & 7 & 4 & 0.64 \\
198 & F & 28 & Eur. & Social Work & 9 & 8 & 5 & 9 & 3 & 6 & 6 & 9 & 9 & 5 & 0.64 \\
369 & F & 28 & Eur. & German Lit. & 7 & 10 & 7 & 10 & 7 & 1 & 10 & 10 & 10 & 5 & 0.64 \\
370 & F & 29 & Oth. & Psychology & 7 & 9 & 9 & 9 & 9 & 3 & 9 & 7 & 5 & 9 & 0.64 \\
194 & F & 22 & Eur. & Social Work & 8 & 9 & 7 & 10 & 7 & 8 & 5 & 7 & 9 & 5 & 0.64 \\
382 & F & 22 & Eur. & Comm. & 7 & 9 & 9 & 9 & 4 & 2 & 10 & 10 & 4 & 1 & 0.64 \\
383 & F & 22 & Eur. & Social Work & 6 & 8 & 8 & 8 & 8 & 7 & 10 & 8 & 6 & 10 & 0.64 \\
\hline
\end{tabular}
\caption{Top 10 recommended partners for sample participant A.}
\label{tab:top10-recommendations}
\end{table}

% Table~\ref{tab:composite-profile} presents the composite profile B*, constructed by averaging the characteristics of the top 10 recommended partners shown in Table~\ref{tab:top10-recommendations}. This aggregated profile represents the ``ideal partner type'' that participant A would most likely prefer, based on the model's predictions.

\begin{table}[H]
\raggedright
\begin{tabular}{@{}lr@{}}
\hline
\textbf{Attribute} & \textbf{Value} \\
\hline
Age & 26.2 \\
Attractive & 7.7 \\
Sincere & 9.0 \\
Intelligence & 7.7 \\
Funny & 9.0 \\
Ambition & 7.3 \\
Sports & 5.6 \\
Music & 8.5 \\
Movies & 8.6 \\
Reading & 6.7 \\
Exercise & 6.6 \\
Gender & Female \\
Race & European/Caucasian-American \\
Field & Social Work \\
\hline
\end{tabular}
\caption{Composite profile B* derived by averaging the top 10 recommended partners for participant A. Numeric values represent means across all candidates; categorical values represent the mode (most common value).}
\label{tab:composite-profile}
\end{table}

% \appendix

% \section{Example Appendix}
% \label{sec:appendix}

% This is an appendix.

\end{document}
